{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('random_3000_with_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>content</th>\n",
       "      <th>like_num</th>\n",
       "      <th>repost_num</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>manually_label</th>\n",
       "      <th>sentiment_baseline</th>\n",
       "      <th>senti_by_refined_snownlp</th>\n",
       "      <th>senti_by_jieba_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10289</td>\n",
       "      <td>2670985301</td>\n",
       "      <td>2020-02-08 23:52</td>\n",
       "      <td>抗击疫情 我们誓死不退（祝洛东）  #武汉加油##抗击新型肺炎我们在行动##抗疫行动##万众...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33252</td>\n",
       "      <td>5622277724</td>\n",
       "      <td>2020-03-06 23:22</td>\n",
       "      <td>#甘肃新增17例境外输入新冠肺炎# 又来[费解]晕死真的是</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15869</td>\n",
       "      <td>5936449524</td>\n",
       "      <td>2020-02-15 23:54</td>\n",
       "      <td>#新冠肺炎已开始在日本流行# 我靠</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14422</td>\n",
       "      <td>2211096821</td>\n",
       "      <td>2020-02-13 23:59</td>\n",
       "      <td>日本再确诊1例新冠肺炎病例 总确诊数已达251例 http://t.cn/A6hGfqoZ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23309</td>\n",
       "      <td>6303064815</td>\n",
       "      <td>2020-02-23 23:59</td>\n",
       "      <td>//@微博辟谣:#微博辟谣# 金银潭医院：军运会五外籍运动员患的都是疟疾，与新冠肺炎无关</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index     user_id        created_at  \\\n",
       "0  10289  2670985301  2020-02-08 23:52   \n",
       "1  33252  5622277724  2020-03-06 23:22   \n",
       "2  15869  5936449524  2020-02-15 23:54   \n",
       "3  14422  2211096821  2020-02-13 23:59   \n",
       "4  23309  6303064815  2020-02-23 23:59   \n",
       "\n",
       "                                             content  like_num  repost_num  \\\n",
       "0  抗击疫情 我们誓死不退（祝洛东）  #武汉加油##抗击新型肺炎我们在行动##抗疫行动##万众...         6           0   \n",
       "1                      #甘肃新增17例境外输入新冠肺炎# 又来[费解]晕死真的是         1           0   \n",
       "2                                  #新冠肺炎已开始在日本流行# 我靠         0           0   \n",
       "3      日本再确诊1例新冠肺炎病例 总确诊数已达251例 http://t.cn/A6hGfqoZ         0           0   \n",
       "4       //@微博辟谣:#微博辟谣# 金银潭医院：军运会五外籍运动员患的都是疟疾，与新冠肺炎无关         0           0   \n",
       "\n",
       "   comment_num  manually_label  sentiment_baseline  senti_by_refined_snownlp  \\\n",
       "0            0               1                   1                         1   \n",
       "1            1               0                  -1                        -1   \n",
       "2            0               0                   0                         0   \n",
       "3            0               0                  -1                        -1   \n",
       "4            0               0                   1                        -1   \n",
       "\n",
       "   senti_by_jieba_sentiment  \n",
       "0                         1  \n",
       "1                         1  \n",
       "2                         1  \n",
       "3                         1  \n",
       "4                         1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>content</th>\n",
       "      <th>like_num</th>\n",
       "      <th>repost_num</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>manually_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10289</td>\n",
       "      <td>2670985301</td>\n",
       "      <td>2020-02-08 23:52</td>\n",
       "      <td>抗击疫情 我们誓死不退（祝洛东）  #武汉加油##抗击新型肺炎我们在行动##抗疫行动##万众...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33252</td>\n",
       "      <td>5622277724</td>\n",
       "      <td>2020-03-06 23:22</td>\n",
       "      <td>#甘肃新增17例境外输入新冠肺炎# 又来[费解]晕死真的是</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15869</td>\n",
       "      <td>5936449524</td>\n",
       "      <td>2020-02-15 23:54</td>\n",
       "      <td>#新冠肺炎已开始在日本流行# 我靠</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14422</td>\n",
       "      <td>2211096821</td>\n",
       "      <td>2020-02-13 23:59</td>\n",
       "      <td>日本再确诊1例新冠肺炎病例 总确诊数已达251例 http://t.cn/A6hGfqoZ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23309</td>\n",
       "      <td>6303064815</td>\n",
       "      <td>2020-02-23 23:59</td>\n",
       "      <td>//@微博辟谣:#微博辟谣# 金银潭医院：军运会五外籍运动员患的都是疟疾，与新冠肺炎无关</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index     user_id        created_at  \\\n",
       "0  10289  2670985301  2020-02-08 23:52   \n",
       "1  33252  5622277724  2020-03-06 23:22   \n",
       "2  15869  5936449524  2020-02-15 23:54   \n",
       "3  14422  2211096821  2020-02-13 23:59   \n",
       "4  23309  6303064815  2020-02-23 23:59   \n",
       "\n",
       "                                             content  like_num  repost_num  \\\n",
       "0  抗击疫情 我们誓死不退（祝洛东）  #武汉加油##抗击新型肺炎我们在行动##抗疫行动##万众...         6           0   \n",
       "1                      #甘肃新增17例境外输入新冠肺炎# 又来[费解]晕死真的是         1           0   \n",
       "2                                  #新冠肺炎已开始在日本流行# 我靠         0           0   \n",
       "3      日本再确诊1例新冠肺炎病例 总确诊数已达251例 http://t.cn/A6hGfqoZ         0           0   \n",
       "4       //@微博辟谣:#微博辟谣# 金银潭医院：军运会五外籍运动员患的都是疟疾，与新冠肺炎无关         0           0   \n",
       "\n",
       "   comment_num  manually_label  \n",
       "0            0               1  \n",
       "1            1               0  \n",
       "2            0               0  \n",
       "3            0               0  \n",
       "4            0               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['sentiment_baseline','senti_by_refined_snownlp','senti_by_jieba_sentiment'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = []\n",
    "for comm in df.content.tolist():\n",
    "    text = re.sub(r'(http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+)','',comm)\n",
    "    text = re.sub(r'(?:回复)?(?://)?@[\\w\\u2E80-\\u9FFF]+:?|\\[\\w+\\]', ',',text)\n",
    "    r='[’！？：；【】，、《》!\"#$%&\\'()（）“”…*+,-./:;<=>?@[\\\\]^_`{|}~]+'\n",
    "    text = re.sub(r, '', text)\n",
    "    content_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = content_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\asus\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.761 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>content</th>\n",
       "      <th>like_num</th>\n",
       "      <th>repost_num</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>manually_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10289</td>\n",
       "      <td>2670985301</td>\n",
       "      <td>2020-02-08 23:52</td>\n",
       "      <td>抗击 疫情   我们 誓死 不退 祝 洛东     武汉 加油 抗击 新型 肺炎 我们 在 ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33252</td>\n",
       "      <td>5622277724</td>\n",
       "      <td>2020-03-06 23:22</td>\n",
       "      <td>甘肃 新增 17 例 境外 输入 新冠 肺炎   又 来 晕死 真的 是</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15869</td>\n",
       "      <td>5936449524</td>\n",
       "      <td>2020-02-15 23:54</td>\n",
       "      <td>新冠 肺炎 已 开始 在 日本 流行   我 靠</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14422</td>\n",
       "      <td>2211096821</td>\n",
       "      <td>2020-02-13 23:59</td>\n",
       "      <td>日本 再 确诊 1 例新冠 肺炎 病例   总 确诊 数已 达 251 例</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23309</td>\n",
       "      <td>6303064815</td>\n",
       "      <td>2020-02-23 23:59</td>\n",
       "      <td>微博 辟谣   金银 潭 医院 军运会 五 外籍 运动员 患 的 都 是 疟疾 与 新冠 肺...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index     user_id        created_at  \\\n",
       "0  10289  2670985301  2020-02-08 23:52   \n",
       "1  33252  5622277724  2020-03-06 23:22   \n",
       "2  15869  5936449524  2020-02-15 23:54   \n",
       "3  14422  2211096821  2020-02-13 23:59   \n",
       "4  23309  6303064815  2020-02-23 23:59   \n",
       "\n",
       "                                             content  like_num  repost_num  \\\n",
       "0  抗击 疫情   我们 誓死 不退 祝 洛东     武汉 加油 抗击 新型 肺炎 我们 在 ...         6           0   \n",
       "1               甘肃 新增 17 例 境外 输入 新冠 肺炎   又 来 晕死 真的 是         1           0   \n",
       "2                           新冠 肺炎 已 开始 在 日本 流行   我 靠         0           0   \n",
       "3            日本 再 确诊 1 例新冠 肺炎 病例   总 确诊 数已 达 251 例           0           0   \n",
       "4  微博 辟谣   金银 潭 医院 军运会 五 外籍 运动员 患 的 都 是 疟疾 与 新冠 肺...         0           0   \n",
       "\n",
       "   comment_num  manually_label  \n",
       "0            0               1  \n",
       "1            1               0  \n",
       "2            0               0  \n",
       "3            0               0  \n",
       "4            0               0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "df['content'] = df['content'].apply(lambda i:jieba.cut(i) )\n",
    "df['content'] =[' '.join(i) for i in df['content']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400,)\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "y = df.manually_label.values\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(df.content.values, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2, shuffle=True)\n",
    "print (x_train.shape)\n",
    "print (x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"对数损失度量（Logarithmic Loss  Metric）的多分类版本。\n",
    "    :param actual: 包含actual target classes的数组\n",
    "    :param predicted: 分类预测结果矩阵, 每个类别都有一个概率\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_normalizer(tokens):\n",
    "    \"\"\" 将所有数字标记映射为一个占位符（Placeholder）。\n",
    "    对于许多实际应用场景来说，以数字开头的tokens不是很有用，\n",
    "    但这样tokens的存在也有一定相关性。 通过将所有数字都表示成同一个符号，可以达到降维的目的。\n",
    "    \"\"\"\n",
    "    return (\"#NUMBER\" if token[0].isdigit() else token for token in tokens)\n",
    "\n",
    "\n",
    "class NumberNormalizingVectorizer(TfidfVectorizer):\n",
    "    def build_tokenizer(self):\n",
    "        tokenize = super(NumberNormalizingVectorizer, self).build_tokenizer()\n",
    "        return lambda doc: list(number_normalizer(tokenize(doc)))\n",
    "\n",
    "stwlist=[line.strip() for line in open('cn_stopwords.txt',\n",
    "'r',encoding='utf-8').readlines()]\n",
    "tfv = NumberNormalizingVectorizer(min_df=3,  \n",
    "                                  max_df=0.5,\n",
    "                                  max_features=None,                 \n",
    "                                  ngram_range=(1,2), \n",
    "                                  use_idf=True,\n",
    "                                  smooth_idf=True,\n",
    "                                  stop_words = stwlist)\n",
    "\n",
    "tfv.fit(list(x_train) + list(x_valid))\n",
    "x_train_tfv =  tfv.transform(x_train) \n",
    "x_valid_tfv = tfv.transform(x_valid)\n",
    "\n",
    "tfv.fit(list(x_train) + list(x_valid))\n",
    "x_train_tfv =  tfv.transform(x_train) \n",
    "x_valid_tfv = tfv.transform(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.765 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.43      0.54       161\n",
      "           0       0.62      0.85      0.72       258\n",
      "           1       0.73      0.60      0.66       181\n",
      "\n",
      "    accuracy                           0.66       600\n",
      "   macro avg       0.69      0.63      0.64       600\n",
      "weighted avg       0.68      0.66      0.65       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_tfv, y_train)\n",
    "y_pred_proba = clf.predict_proba(x_valid_tfv)\n",
    "y_pred = clf.predict(x_valid_tfv)\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, y_pred_proba))\n",
    "print(classification_report(y_valid, y_pred,target_names = ['-1','0','1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.633 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.53      0.58       161\n",
      "           0       0.64      0.79      0.71       258\n",
      "           1       0.76      0.61      0.68       181\n",
      "\n",
      "    accuracy                           0.67       600\n",
      "   macro avg       0.68      0.65      0.66       600\n",
      "weighted avg       0.68      0.67      0.67       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1.0,solver='lbfgs',multi_class='multinomial')\n",
    "clf.fit(x_train_tfv, y_train)\n",
    "y_pred_proba = clf.predict_proba(x_valid_tfv)\n",
    "y_pred = clf.predict(x_valid_tfv)\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, y_pred_proba))\n",
    "print(classification_report(y_valid, y_pred,target_names = ['-1','0','1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.926 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.47      0.52       161\n",
      "           0       0.60      0.79      0.68       258\n",
      "           1       0.74      0.56      0.64       181\n",
      "\n",
      "    accuracy                           0.63       600\n",
      "   macro avg       0.65      0.61      0.62       600\n",
      "weighted avg       0.64      0.63      0.63       600\n",
      "\n",
      "Wall time: 8.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = SVC(C=1.0,kernel='rbf',probability=True)\n",
    "clf.fit(x_train_tfv, y_train)\n",
    "y_pred_proba = clf.predict_proba(x_valid_tfv)\n",
    "y_pred = clf.predict(x_valid_tfv)\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, y_pred_proba))\n",
    "print(classification_report(y_valid, y_pred,target_names = ['-1','0','1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 2.097 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.55      0.57       161\n",
      "           0       0.65      0.75      0.70       258\n",
      "           1       0.73      0.62      0.67       181\n",
      "\n",
      "    accuracy                           0.66       600\n",
      "   macro avg       0.66      0.64      0.65       600\n",
      "weighted avg       0.66      0.66      0.65       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(x_train_tfv, y_train)\n",
    "y_pred_proba = clf.predict_proba(x_valid_tfv)\n",
    "y_pred = clf.predict(x_valid_tfv)\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_valid, y_pred_proba))\n",
    "print(classification_report(y_valid, y_pred,target_names = ['-1','0','1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
